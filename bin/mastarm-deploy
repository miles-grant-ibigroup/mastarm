#!/usr/bin/env node

const path = require('path')

const commander = require('commander')
const execa = require('execa')
const fs = require('fs-extra')
const gitRepoIsUpToDate = require('git-repo-is-up-to-date')
const commit = require('this-commit')()
const username = require('username')
const { readFile, writeFile } = require('fs-extra')

const build = require('../lib/build')
const loadConfig = require('../lib/load-config')
const logger = require('../lib/logger')
const pkg = require('../lib/pkg')
const createPushToS3 = require('../lib/push-to-s3')
const util = require('../lib/util')
const mastarmVersion = require('../package.json').version

commander
  .option(
    '-c, --config <path>',
    'Path to configuration files.',
    path.join(process.cwd(), '/configurations/default')
  )
  .option('-e, --env <environment>', 'Environment to use.')
  .option('-m, --minify', 'Minify built files.')
  .option('-O, --outdir <dir>', 'Publish directory', '')
  .option('--cloudfront <id>', 'CloudFront Distribution ID to invalidate.')
  .option('--s3bucket <bucket>', 'S3 Bucket to push to.')
  .option(
    '--static-file-directory <dir>',
    'Directory of static files to deploy in lieu of building'
  )
  .parse(process.argv)

// each of these variables are also used in the logToMsTeams function and
// these need to be defined after potentially decoding a sops-encoded file
let cloudfront, config, env, minify, s3bucket, tag, url

async function deploy() {
  // get information about the directory that the config is in
  const configRepoStatus = await gitRepoIsUpToDate(commander.config)
  const { remoteUrl: configRemoteUrl, repoInfo } = configRepoStatus
  let configCommit, configDir
  if (repoInfo) {
    configCommit = repoInfo.localCommit
    configDir = repoInfo.root
  }

  // do some extra analysis if it looks like a configurations repo is being used
  if (configRemoteUrl && configRemoteUrl.endsWith('/configurations.git')) {
    if (!configRepoStatus.isUpToDate) {
      console.error('Configurations folder is not up-to-date! Errors:')
      configRepoStatus.errors.forEach((err) => console.error(err))
      process.exit(1)
    }

    // no decryption needed during workflow to upload just static files
    if (!commander.staticFileDirectory) {
      // decrypt env file using sops to make sure old file is overwritten with
      // data from encoded sops file
      const configPath = path.resolve(commander.config)
      console.log('decrypting env file with sops')
      const { stdout } = await execa('sops', [
        '-d',
        path.join(configPath, 'env.enc.yml')
      ])
      await writeFile(path.join(configPath, 'env.yml'), stdout)
    }
    // at this point, we can be certain that the local configurations repo
    // directory matches what has been committed and pushed to the remote repo
  }

  url = pkg.repository.url.replace('.git', '')
  tag = `<${url}/commit/${commit}|${pkg.name}@${commit.slice(0, 6)}>`
  config = loadConfig(process.cwd(), commander.config, commander.env)
  const get = util.makeGetFn([commander, config.settings])

  if (config.env.SLACK_WEBHOOK && config.env.SLACK_WEBHOOK.length > 0) {
    logger.logToSlack({
      channel: config.env.SLACK_CHANNEL || '#devops',
      webhook: config.env.SLACK_WEBHOOK
    })
  }

  env = get('env') || 'development'
  minify = get('minify')
  cloudfront = get('cloudfront')
  s3bucket = get('s3bucket')

  const pushToS3 = createPushToS3({
    cloudfront,
    s3bucket
  })

  await logger.log(
    `:construction: *deploying: ${tag} by <@${username.sync()}>*
    :vertical_traffic_light: *mastarm:* v${mastarmVersion}
    :cloud: *cloudfront:* ${cloudfront}
    :hash: *commit:* ${commit}
    :seedling: *env:* ${env}
    :compression: *minify:* ${minify}
    :package: *s3bucket:* ${s3bucket}`
  )
  let outfiles
  try {
    // If the flag staticFileDirectory is set, upload all files found in
    // the base level of the given directory.
    if (commander.staticFileDirectory) {
      const staticDirPath = path.resolve(commander.staticFileDirectory)
      process.chdir(staticDirPath)
      outfiles = []
      const files = await fs.readdir(staticDirPath)
      await Promise.all(
        files.map(async (file) => {
          const fileStats = await fs.stat(file)
          if (!fileStats.isDirectory()) {
            outfiles.push(file)
          }
        })
      )
      await logger.log(`:rocket: *uploading:* ${outfiles.length} file(s)`)
    } else {
      // Otherwise, upload the files specified with the entries arg.
      const files = util.parseEntries([
        ...commander.args,
        ...(get('entries') || [])
      ])
      // assert that the files exist if not uploading from static file directory
      util.assertEntriesExist(files)
      // build files using mastarm build
      outfiles = [...files.map((f) => f[1]), ...files.map((f) => `${f[1]}.map`)]
      const sourceFiles = files.map((f) => f[0])
      await logger.log(
        `:hammer_and_wrench: *building:* ${sourceFiles.join(', ')}`
      )
      const buildOpts = {
        config,
        env,
        files,
        minify
      }
      await build(buildOpts)
      await logger.log(
        `:rocket: *uploading:* ${sourceFiles.length * 2} file(s)`
      )
    }

    // upload files to s3 and invalid cloudfront if needed
    await Promise.all(
      outfiles.map(async (outfile) => {
        const body = await readFile(outfile)
        await pushToS3({ body, outfile })
      })
    )

    // pronounce success!
    await logger.log(
      `:tada: :confetti_ball: :tada: *deploy ${tag} complete* :tada: :confetti_ball: :tada:`
    )
    await logToMsTeams({ configCommit, configDir, configRemoteUrl })
    process.exit(0)
  } catch (error) {
    await logger.log(
      `:rotating_light: *${tag} error deploying ${tag} ${
        error.message || error
      }*`
    )
    await logToMsTeams({ configCommit, configDir, configRemoteUrl, error })
    process.exit(1)
  }
}

deploy()

/**
 * Sends a card to MS Teams with information about the deployment
 * @param  {[string]} configCommit   hash of the commit in the configurations
 *                          repo (if it exists)
 * @param  {[string]} configDir   partial path to specific config directory used
 *                          to deploy
 * @param  {[string]} configRemoteUrl base url for the configurations repo
 *                          (if it exists)
 * @param  {[Error]} error the error, if one occurred. A falsy value indicates
 *                          success
 */
function logToMsTeams({ configCommit, configDir, configRemoteUrl, error }) {
  if (!config.env.MS_TEAMS_WEBHOOK) return Promise.resolve()

  const potentialAction = [
    {
      '@type': 'OpenUri',
      name: 'View Commit on Github',
      targets: [
        {
          os: 'default',
          uri: `${url}/commit/${commit}`
        }
      ]
    }
  ]
  if (configCommit && configRemoteUrl) {
    potentialAction.push({
      '@type': 'OpenUri',
      name: 'View Config Commit on Github',
      targets: [
        {
          os: 'default',
          uri: `${configRemoteUrl}/tree/${configCommit}/${configDir}`
        }
      ]
    })
  }
  const text = `📄 **commit:** ${pkg.name}@${commit.slice(0, 6)}\n
  👤 **deployed by:** ${username.sync()}\n
  ${
    configCommit
      ? `🎛️ **config:** configurations@${configCommit.slice(0, 6)}\n
  📂 **config folder:** ${configDir}\n` // improper indenting here needed to properly format on MS Teams
      : '🎛️ **config:** unknown configuration data!\n'
  }
  🚦 **mastarm:** v${mastarmVersion}\n
  ☁️ **cloudfront:** ${cloudfront}\n
  🌱 **env:** ${env}\n
  🗜️ **minify:** ${minify}\n
  📦 **s3bucket:** ${s3bucket}\n
  ${
    error
      ? `🚨 🚨 **error deploying ${error.message || error}**`
      : '🎉 🎊 🎉 **deploy successful!** 🎉 🎊 🎉'
  }`

  return logger.notifyMsTeams({
    potentialAction,
    text,
    title: `${error ? 'Failed to deploy' : 'Successfully deployed'} ${
      pkg.name
    }`,
    webhook: config.env.MS_TEAMS_WEBHOOK
  })
}
